import tensorflow as tf

m1 = tf.constant([[2,1]])
m2 = tf.constant([[2],[5]])

product = tf.matmul(m1,m2)

with tf.Session() as sess:
    print(sess.run(product))
    print(product)
    sess.close()
    
x = tf.Variable([1,2])
a = tf.constant([3,3])

sub = tf.subtract(x,a)
add = tf.add(x,sub)


init = tf.initialize_all_variables()

with tf.Session() as sess:
    sess.run(init)
    print(sess.run(sub))
    print(sess.run(add))
    sess.close()


state = tf.Variable(0,name="counter")

ew_value = tf.add(state,1)
update = tf.assign(state,new_value)
init = tf.initialize_all_variables()
with tf.Session() as sess:
    sess.run(init)
    print(sess.run(state))
    for i in range(6):
        sess.run(update)
        print(sess.run(state))


input1 = tf.constant(3.0)
input2 = tf.constant(2.0)
input3 = tf.constant(5.0)

add = tf.add(input2,input3)
mul = tf.multiply(input1,add)

with tf.Session() as sess:
    result = sess.run([mul,add])
    print(result)
    
 
 input1 = tf.placeholder(tf.float32)
input2 = tf.placeholder(tf.float32)
output = tf.multiply(input1,input2)
with tf.Session() as sess:
    print(sess.run(output,feed_dict={input1:[7.],input2:[3.]}))


#实例讲解
import numpy as np

x_data = np.random.rand(100)
y_data = x_data * 0.1 + 0.2

#构造线性模型
b = tf.Variable(0.)
k = tf.Variable(0.)
y = k * x_data + b

#定义二次代价函数
loss = tf.reduce_mean(tf.square(y_data - y))
#定义梯度下降算法
optimizer = tf.train.GradientDescentOptimizer(0.2)
#最小化代价函数
train = optimizer.minimize(loss)
init = tf.initialize_all_variables()

with tf.Session() as sess:
    sess.run(init)
    for i in range(201):
        sess.run(train)
        if i % 10 == 0:
            print(i,sess.run([k,b]))
        
 
 
 
